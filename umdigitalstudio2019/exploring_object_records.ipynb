{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring object records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll have a preliminary poke around in the `object` data harvested from the [NMA Collection API](https://www.nma.gov.au/about/our-collection/our-apis). I'll focus here on the basic shape/stats of the data, other notebooks will explore the object data over [time](explore_collection_object_over_time.ipynb) and [space](explore_objects_and_places.ipynb).\n",
    "\n",
    "If you haven't already, you'll either need to [harvest the `object` data](harvest_records.ipynb), or [unzip a pre-harvested dataset](unzip_preharvested_data.ipynb).\n",
    "\n",
    "* [The shape of the data](#The-shape-of-the-data)\n",
    "* [Nested data](#Nested-data)\n",
    "* [The `additionalType` field](#The-additionalType-field)\n",
    "* [The `extent` field](#The-extent-field)\n",
    "* [How big is the collection?](#How-big-is-the-collection?)\n",
    "* [The biggest object?](#The-biggest-object?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>If you haven't used one of these notebooks before, they're basically web pages in which you can write, edit, and run live code. They're meant to encourage experimentation, so don't feel nervous. Just try running a few cells and see what happens!</p>\n",
    "\n",
    "<p>\n",
    "    Some tips:\n",
    "    <ul>\n",
    "        <li>Code cells have boxes around them.</li>\n",
    "        <li>To run a code cell click on the cell and then hit <b>Shift+Enter</b>. The <b>Shift+Enter</b> combo will also move you to the next cell, so it's a quick way to work through the notebook.</li>\n",
    "        <li>While a cell is running a <b>*</b> appears in the square brackets next to the cell. Once the cell has finished running the asterix will be replaced with a number.</li>\n",
    "        <li>In most cases you'll want to start from the top of notebook and work your way down running each cell in turn. Later cells might depend on the results of earlier ones.</li>\n",
    "        <li>To edit a code cell, just click on it and type stuff. Remember to run the cell once you've finished editing.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "<p><b>Is this thing on?</b> If you can't edit or run any of the code cells, you might be viewing a static (read only) version of this notebook. Click here to <a href=\"https://mybinder.org/v2/gh/GLAM-Workbench/national-museum-australia/master?urlpath=lab%2Ftree%2Fexploring_object_records.ipynb\">load a <b>live</b> version</a> running on Binder.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from IPython.display import display, HTML, FileLink\n",
    "from tinydb import TinyDB, Query\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the harvested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the harvested data from the json db\n",
    "db = TinyDB('nma_object_db.json')\n",
    "records = db.all()\n",
    "Object = Query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a dataframe\n",
    "df = pd.DataFrame(records)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The shape of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many objects are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {:,} objects in the collection'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously not every record has a value for every field, let's create a quick count of the number of values in each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's express those counts as a percentage of the total number of records, and display them as a bar chart using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get field counts and convert to dataframe\n",
    "field_counts = df.count().to_frame().reset_index()\n",
    "\n",
    "# Change column headings\n",
    "field_counts.columns = ['field', 'count']\n",
    "\n",
    "# Calculate proportion of the total\n",
    "field_counts['proportion'] = field_counts['count'].apply(lambda x: x / df.shape[0])\n",
    "\n",
    "# Style the results as a barchart\n",
    "field_counts.style.bar(subset=['proportion'], color='#d65f5f').format({'proportion': '{:.2%}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you might note is that some of the fields contain nested JSON arrays or objects. For example `additionalType` contains a list of object types, while `extent` is a dictionary with keys and values. Let's unpack these columns for the second row (index of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['additionalType'][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extent'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extent'][1]['length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `additionalType` field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many objects have values in the `additionalType` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['additionalType'].notnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:%} of objects have an additionalType value'.format(df.loc[df['additionalType'].notnull()].shape[0] / df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So which ones don't have an `additionalType`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just show the first 5 rows\n",
    "df.loc[df['additionalType'].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows have more than one `additionalType`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['additionalType'].str.len() > 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['additionalType'].str.len() > 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `additionalType` field contains a nested list of values. Using `json_normalize()` or `explode()` we can explode these lists, creating a row for each separate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use json_normalize to expand 'additionalType' into separate rows, adding the id and title from the parent record\n",
    "# df_types = json_normalize(df.loc[df['additionalType'].notnull()].to_dict('records'), record_path='additionalType', meta=['id', 'title'], errors='ignore').rename({0: 'additionalType'}, axis=1)\n",
    "\n",
    "# In pandas v.0.25 and above you can just use explode -- this prodices the same result as above\n",
    "df_types = df.loc[df['additionalType'].notnull()][['id', 'title', 'additionalType']].explode('additionalType')\n",
    "\n",
    "df_types.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've exploded the type values, we can aggregate them in different ways. Let's look at the 25 most common object types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_types['additionalType'].value_counts()[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many object types only appear once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_counts = df_types['additionalType'].value_counts().to_frame().reset_index().rename({'index': 'type', 'additionalType': 'count'}, axis=1)\n",
    "unique_types = type_counts.loc[type_counts['count'] == 1]\n",
    "unique_types.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the complete list of types as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_counts.to_csv('nma_object_type_counts.csv', index=False)\n",
    "display(FileLink('nma_object_type_counts.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browsing the CSV I noticed that there was one item with the type `Vegetables`. Let's find some more out about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find in the complete data set\n",
    "mask = df.loc[df['additionalType'].notnull()]['additionalType'].apply(lambda x: 'Vegetables' in x)\n",
    "veggie = df.loc[df['additionalType'].notnull()][mask]\n",
    "veggie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a link into the NMA Collections Explorer using the object `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<a href=\"http://collectionsearch.nma.gov.au/?object={}\">{}</a>'.format(veggie.iloc[0]['id'], veggie.iloc[0]['title'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does a toad stool count as a vegetable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `extent` field\n",
    "\n",
    "The `extent` field is a nested object, so once again we'll use `json_normalize()` to expand it out into separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without reset_index() the rows are misaligned\n",
    "df_extent = df.loc[df['extent'].notnull()].reset_index().join(json_normalize(df.loc[df['extent'].notnull()]['extent'].tolist()).add_prefix(\"extent_\"))\n",
    "df_extent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see what types of things are in the `extent` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extent['extent_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So they're all measurements. Let's have a look at the units being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extent['extent_unitText'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extent['extent_unitTextWeight'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, are those measurements really in metres, or might they be meant to be 'mm'? Let's have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extent.loc[df_extent['extent_unitText'] == 'm'][['id', 'title', 'extent_length', 'extent_width', 'extent_unitText']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than 'Gunter's chain' it looks like the unit should indeed by 'mm'. We'll need to take that into account in calculations.\n",
    "\n",
    "Now let's convert all the measurements into a single unit – millimetre for lengths, and gram for weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_factor(unit):\n",
    "    '''\n",
    "    Get the factor required to convery current unit to either mm or g.\n",
    "    '''\n",
    "    factors = {\n",
    "        'mm': 1,\n",
    "        'cm': 10,\n",
    "        'm': 1, # Most should in fact be mm (see above)\n",
    "        'g': 1,\n",
    "        'kg': 1000,\n",
    "        'tonne': 1000000,\n",
    "        'oz': 28.35,\n",
    "        'lb': 453.592\n",
    "    }\n",
    "    try:\n",
    "        factor = factors[unit.lower()]\n",
    "    except KeyError:\n",
    "        factor = 0 \n",
    "    return factor\n",
    "\n",
    "def normalise_measurements(row):\n",
    "    '''\n",
    "    Convert measurements to standard units.\n",
    "    '''\n",
    "    l_factor = conversion_factor(str(row['extent_unitText']))\n",
    "    length = row['extent_length'] * l_factor\n",
    "    width = row['extent_width'] * l_factor\n",
    "    depth = row['extent_depth'] * l_factor\n",
    "    height = row['extent_height'] * l_factor\n",
    "    diameter = row['extent_diameter'] * l_factor\n",
    "    w_factor = conversion_factor(str(row['extent_unitTextWeight']))\n",
    "    weight = row['extent_weight'] * w_factor\n",
    "    return pd.Series([length, width, depth, height, diameter, weight])\n",
    "\n",
    "# Add normalised measurements to the dataframe\n",
    "df_extent[['length_mm', 'width_mm', 'depth_mm', 'height_mm', 'diameter_mm', 'weight_g']] = df_extent.apply(normalise_measurements, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How big is the collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_volume(row):\n",
    "    '''\n",
    "    Look for 3 linear dimensions and multiply them to get a volume.\n",
    "    '''\n",
    "    # Create a list of valid linear measurements from the available fields\n",
    "    dimensions = [d for d in [row['length_mm'], row['width_mm'], row['depth_mm'], row['height_mm'], row['diameter_mm']] if not math.isnan(d)]\n",
    "    \n",
    "    # If there's only 2 dimensions...\n",
    "    if len(dimensions) == 2:\n",
    "        # Set a default height of 1 for items with only 2 dimensions\n",
    "        dimensions.append(1)\n",
    "        \n",
    "    # If there's 3 or more dimensions, multiple the first 3 together\n",
    "    if len(dimensions) >= 3:\n",
    "        volume = dimensions[0] * dimensions[1] * dimensions[2]\n",
    "    else:\n",
    "        volume = 0\n",
    "    return volume\n",
    "\n",
    "df_extent['volume'] = df_extent.apply(calculate_volume, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total length of objects is {:.2f} km'.format(df_extent['length_mm'].sum() / 1000 / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total weight of objects is {:.2f} tonnes'.format(df_extent['weight_g'].sum() / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total volume of objects is {:.2f} m\\N{SUPERSCRIPT THREE}'.format(df_extent['volume'].sum() / 1000000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The biggest object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the biggest thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the object with the largest volume\n",
    "biggest = df_extent.loc[df_extent['volume'].idxmax()]\n",
    "\n",
    "# Create a link to Collection Explorer\n",
    "display(HTML('<a href=\"http://collectionsearch.nma.gov.au/?object={}\">{}</a>'.format(biggest['id'], biggest['title'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Created by [Tim Sherratt](https://timsherratt.org/) for the [GLAM Workbench](https://glam-workbench.github.io/).\n",
    "\n",
    "Work on this notebook was supported by the [Humanities, Arts and Social Sciences (HASS) Data Enhanced Virtual Lab](https://tinker.edu.au/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
